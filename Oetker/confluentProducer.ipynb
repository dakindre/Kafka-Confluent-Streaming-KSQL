{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oetker Streaming Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Run following command in KSQL prompt:\n",
    "    \n",
    "    ```RUN SCRIPT 'confluentConsumer.ksql';```\n",
    "    \n",
    "\n",
    "2. To view results of windowed unique user aggregation in KSQL type the following:\n",
    "\n",
    "    ```SELECT ROWKEY, UNIQUE_USERS FROM UNIQUE_USERS;```\n",
    "    To stop type:`Ctrl-C:`\n",
    "    \n",
    "    \n",
    "3. View analysis in the Control [Console](http://localhost:9021/)\n",
    "\n",
    "\n",
    "4. Navigate to Development-KSQL-Query Editor\n",
    "\n",
    "\n",
    "5. To view results of non windowed country counts type the following:\n",
    "\n",
    "    ```SELECT ROWTIME, COUNTRY, COUNTRYCOUNT FROM COUNTRY_AGG;```\n",
    "\n",
    "\n",
    "6. Run the script below under the Producer Heading to begin the Kafka Stream\n",
    "\n",
    "\n",
    "7. Once the stream has ended stop both queries and exit KSQL using the below command:\n",
    "\n",
    "    ```exit```\n",
    "\n",
    "\n",
    "8. End Services by running the following script:\n",
    "    \n",
    "    ```sudo ~/Documents/Oetker/./confluentStop```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Explanations\n",
    "\n",
    "### confluentStart\n",
    "\n",
    "    * Install Environment Dependencies\n",
    "    * Install confluent Control Center\n",
    "    * Start Confluent Services\n",
    "    * Install confluent-kafka package\n",
    "    * Create Kafka Topic: `Oetker`\n",
    "    * Start KSQL Client\n",
    "    \n",
    "### confluenConsumer\n",
    "\n",
    "    * USER:                Stream Created from Kafka Topic \n",
    "    * USER_INFO:           Stream Created from USER Topic\n",
    "    * UNIQUE_USERS:        Table Created from USER_INFO\n",
    "    * COUNTRY_AGG:         Table Created from USER Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confluent Justifications/Limitations\n",
    "\n",
    "### Justifications\n",
    "\n",
    "    * Easy integration with kafka streaming\n",
    "    * UI interface for monitoring stream performance and visualizing stream analytics\n",
    "    * KSQL integrates well with JSON kafka stream\n",
    "    * Packaged Kafka Zookeeper KSQL solution\n",
    "\n",
    "### Limitations\n",
    "\n",
    "    * KSQL doesn't allow for aggregations of aggregated table data.\n",
    "    * Not able to select MAX, MIN from COUNT(*) for country\n",
    "    * Limited functionality in syncing queries with data streams\n",
    "    * Still in development/beta phase\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openSource():\n",
    "    try:\n",
    "        with open('Data/MOCK_DATA.json', 'r') as f:\n",
    "            mock = json.load(f)\n",
    "        return mock\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = Producer({'bootstrap.servers': 'localhost:9092', 'plugin.library.paths': 'monitoring-interceptor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Produce():\n",
    "    mock = openSource()\n",
    "    if not mock:\n",
    "        print('Invalid stream file')\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        for line in mock:\n",
    "            producer.poll(0)\n",
    "            producer.produce('oetker', json.dumps(line).encode('utf-8'))\n",
    "            time.sleep(0.1)\n",
    "    producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Produce()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
